---
layout: content
metadata: notebooks_basics_pytorch_intro_metadata
colab: https://colab.research.google.com/github/AIMed-Team/edu-content/blob/master/notebooks/basics/pytorch_intro/index.ipynb
---

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">datasets</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>NOTE</strong>: it is recommended to watch <a href="https://drive.google.com/file/d/1jARX0gjNZwpkcMloOnE8HmngIYDQ6sIB/view?usp=sharing">this link</a> about "Intoduction of how to code in Pytorch" instructed by Rassa Ghavami beforehand.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-is-Tensor?">What is Tensor?<a class="anchor-link" href="#What-is-Tensor?">¶</a></h3><p>tensor is mostly same as numpy array (even its applications like broadcasting operation, indexing, slicing and etc), except for it brings us the opportunity to run operations on faster hardwares like GPU. let's see some tensor defintion</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">arr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="c1"># tensors are defined by default at CPU</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># keep 'size', 'dtype' and 'device' same as arr, but fill with 1</span>
<span class="n">arr2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

<span class="c1"># keep 'dtype' and 'device' same as arr, but fill data arbitrarily</span>
<span class="n">arr3</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">new_tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>in order to feed tensors to deep-learning models, they should follow a customary shape form; <code>B C H W</code> for 4D tensors where <code>B</code> is batch size, <code>C</code> is channel dimension and <code>H W</code> are spatial dimensions.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Device-determination">Device determination<a class="anchor-link" href="#Device-determination">¶</a></h4><p>first we need to determine which device all torch tensors (including the input, learning weights and etc) are going to be allocated. basically, GPU is the first priority.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Pseudo-random-generation">Pseudo random generation<a class="anchor-link" href="#Pseudo-random-generation">¶</a></h4><p>it is often recommended to generate <strong>pseudo</strong> random numbers as it provides fair comparison between different configs of deep learning model(s). torch provides this by <code>torch.manual_seed</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>

<span class="c1"># same seed on all devices; both CPU and CUDA</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-a-CNN-model">Build a CNN model<a class="anchor-link" href="#Build-a-CNN-model">¶</a></h2><p>In this section, you will learn how to build and train a CNN model.</p>
<p>pytorch models are defined as python classes inherited from <code>torch.nn.Module</code>. two functions are essential for model creation:</p>
<ol>
<li>learning weights (parameters) and network layers are defined within <code>__init__()</code>.</li>
<li>forwarding procedure of the model is developed within <code>forward()</code>.</li>
</ol>
<p>so let's create a multi-classification CNN model (with ten ground-truth labels) containing the following layers: <code>Conv</code> -&gt; <code>ReLU</code> -&gt; <code>Batchnorm</code> -&gt; <code>Conv</code> -&gt; <code>ReLU</code> -&gt; <code>Batchnorm</code> -&gt; <code>Adaptive average pooling</code> -&gt; <code>dropout</code> -&gt; <code>fully connected</code>. suppose the input has only one channel and <code>forward()</code> will only return output of the model.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># your code here</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># your code here    </span>
        
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="set-model-device">set model device<a class="anchor-link" href="#set-model-device">¶</a></h4><p>Previously, we have determined which device (GPU or CPU) is going to be used, although it has not been allocated yet to parameters of the model. Pytorch <code>.to(device)</code> Api provides this for us.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-phases">Model phases<a class="anchor-link" href="#Model-phases">¶</a></h4><p>there are two phases for a Pytorch model: <code>.train()</code> and <code>.eval()</code>. models are by default at <code>.train()</code> phase, however the difference between these two is that in <code>eval()</code> phase, some layers change their behavior during inference; for instance dropout will be deactivated and batch normalization will not update estimated mean and variance and they will be used only for normalization, hence please note <strong><code>.eval()</code> will not block parameters to be updated</strong>. therefore during evaluation, besides <code>model.eval()</code> we should assure that back propagation is temporarily deactivated and this is possible by <code>torch.no_grad()</code>. indeed disabling the gradient calculation enables us to use bigger batch sizes as it speeds up the computation and reduces memory usage.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-processing">Data processing<a class="anchor-link" href="#Data-processing">¶</a></h2><p>Before training, we need to prepare and process our dataset which is MNIST here.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Data-transformation">Data transformation<a class="anchor-link" href="#Data-transformation">¶</a></h4><p>PIL images should first be transformed to torch tensors. <code>torchvision.transforms.Compose</code> provides a pipeline of transforms. in the following 'converting to tensors' is only applied.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Download-data">Download data<a class="anchor-link" href="#Download-data">¶</a></h4><p>as evaluation is not purpose of this notebook, you only need to load <strong>train</strong> set of MNIST dataset using <code>torchvision.datasets.MNIST</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># your code here</span>
<span class="n">train</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Data-loader">Data loader<a class="anchor-link" href="#Data-loader">¶</a></h4><p>define train loader using <code>torch.utils.data.DataLoader</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># your code here</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training">Training<a class="anchor-link" href="#Training">¶</a></h2><p>here we are going to develop training process of MNIST classification.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Optimizer">Optimizer<a class="anchor-link" href="#Optimizer">¶</a></h4><p>define your optimizer, use <code>torch.optim</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># your code here</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Procedure">Procedure<a class="anchor-link" href="#Procedure">¶</a></h4><p>implement the procedure of training in the following cell. please note <strong>evaluation is not purpose of this notebook</strong>, therefore only report the training loss changes which ought to be descending in general. consider cross entropy as loss function and compute it without using pre-defined APIs. 
the backpropagation consists of three sub-parts:</p>
<ol>
<li>gradient computation</li>
<li>updating learning parameters</li>
<li>removing current computed gradients for next iteration</li>
</ol>
<p>fortunately we don't need to implement them from sctrach as pytorch provides APIs for them.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_iters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">train_losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> 

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">it</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1">## forward model</span>
        
        <span class="c1">## compute loss</span>
        
        <span class="c1">## backpropagation</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="More-notes">More notes<a class="anchor-link" href="#More-notes">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hooks">Hooks<a class="anchor-link" href="#Hooks">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Hooks are magic</strong> and in Pytorch (which is same as everywhere else), they are functions triggered at some certain points of the process. Currently, Pytorch supports three global hooks: <code>register_forward_pre_hook</code>, <code>register_forward_hook</code> and <code>register_backward_hook</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="register_forward_pre_hook">register_forward_pre_hook<a class="anchor-link" href="#register_forward_pre_hook">¶</a></h4><p>triggers before starting the forward passing of a module and so let's see how it works :). write a hook to check the input <code>x</code> of your <code>forward</code> function has exactly 4 number of dimensions, otherwise throw an exception.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### your code here</span>

<span class="n">incorrect_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="n">correct_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="n">incorrect_x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">model</span><span class="p">(</span><span class="n">incorrect_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"FAILED case1"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"PASSED case1"</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">model</span><span class="p">(</span><span class="n">correct_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"PASSED case2"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"FAILED case2"</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">model</span><span class="p">(</span><span class="n">incorrect_x2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"FAIILED case3"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"PASSED case3"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="register_forward_hook">register_forward_hook<a class="anchor-link" href="#register_forward_hook">¶</a></h4><p>triggers at the end of forward passing of the module. so now write a code to visualize the importance score of each layer given to the input image. the purpose is to recognize which layer pays attention to which part of the image. also choose a sample input by your choice.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### your code here</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="register_backward_hook">register_backward_hook<a class="anchor-link" href="#register_backward_hook">¶</a></h4><p><br/></p>
<html>
<a id="register_backward_hook"></a>
triggers at the end of backward passing of the module. clipping gradient is a way to control the movement in optimization space and to avoid fast parameter updating in order to better explore the optimization space. write a hook to ensure the gradient calculated for each layer is limited to "two" **absolute value**. use it and train again your model from scratch and check how it has varied. Also **unregister the last hook** to avoid repetitive visualizations.</html>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### your code here</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Python-built-in-list-and-dictionary-effect">Python built-in list and dictionary effect<a class="anchor-link" href="#Python-built-in-list-and-dictionary-effect">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Layers and parameters recorded in either of python's list or dictionary will not be registered in graph computation and therefore will not be trained. Instead, it is recommended to use <code>ModuleList</code> and <code>ModuleDict</code>. If you have use it now then please change it :).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Avoid-looping">Avoid looping<a class="anchor-link" href="#Avoid-looping">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using loops extremely slows down the process and it should be avoided by parallel computation as much as possible.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-and-load">Save and load<a class="anchor-link" href="#Save-and-load">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>parameters can be saved using <code>torch.save</code> and passing the <code>state_dict</code> object of the model. In addition, it could be loaded by passing the returned object of <code>torch.load</code> to the model's <code>load_state_dict</code> API.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="gradient-clipping">gradient clipping<a class="anchor-link" href="#gradient-clipping">¶</a></h3><p><a href="#register_backward_hook">Here</a> you have learned how to clip gradients using backward hooks. Also there is an alternative for this which is <code>torch.nn.utils.clip_grad_value_</code> API.</p>
</div>
</div>
</div>
